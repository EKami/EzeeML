{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as aug\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1234\n",
    "np.random.seed(seed)\n",
    "color=sns.color_palette()\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some paths for future use\n",
    "input_path = Path(\"../data\")\n",
    "train_dir = input_path / \"train_data\"\n",
    "test_dir = input_path / \"test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  31072\n"
     ]
    }
   ],
   "source": [
    "# Load the train csv file\n",
    "train_df = pd.read_csv(\"../CSVs/train.csv\")\n",
    "print(\"Number of training samples: \", len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of labels attached to a single sample: 5\n",
      "Minimum number of labels attached to a single sample: 1\n",
      "All counts:\n",
      "1    15126\n",
      "2    12485\n",
      "3     3160\n",
      "4      299\n",
      "5        2\n",
      "Name: nb_labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df[\"nb_labels\"] = train_df[\"Target\"].apply(lambda x: len(x.split(\" \")))\n",
    "print(f\"Maximum number of labels attached to a single sample: {train_df['nb_labels'].max()}\")\n",
    "print(f\"Minimum number of labels attached to a single sample: {train_df['nb_labels'].min()}\")\n",
    "print(\"All counts:\")\n",
    "print(train_df[\"nb_labels\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelmap\n",
    "\n",
    "labels_dict={\n",
    "0:  \"Nucleoplasm\", \n",
    "1:  \"Nuclear membrane\",   \n",
    "2:  \"Nucleoli\",   \n",
    "3:  \"Nucleoli fibrillar center\" ,  \n",
    "4:  \"Nuclear speckles\"   ,\n",
    "5:  \"Nuclear bodies\"   ,\n",
    "6:  \"Endoplasmic reticulum\",   \n",
    "7:  \"Golgi apparatus\"   ,\n",
    "8:  \"Peroxisomes\"   ,\n",
    "9:  \"Endosomes\"   ,\n",
    "10:  \"Lysosomes\"   ,\n",
    "11:  \"Intermediate filaments\",   \n",
    "12:  \"Actin filaments\"   ,\n",
    "13:  \"Focal adhesion sites\",   \n",
    "14:  \"Microtubules\"   ,\n",
    "15:  \"Microtubule ends\",   \n",
    "16:  \"Cytokinetic bridge\",   \n",
    "17:  \"Mitotic spindle\"   ,\n",
    "18:  \"Microtubule organizing center\" ,  \n",
    "19:  \"Centrosome\"   ,\n",
    "20:  \"Lipid droplets\",   \n",
    "21:  \"Plasma membrane\",   \n",
    "22:  \"Cell junctions\"  , \n",
    "23:  \"Mitochondria\"   ,\n",
    "24:  \"Aggresome\"   ,\n",
    "25:  \"Cytosol\",\n",
    "26:  \"Cytoplasmic bodies\",   \n",
    "27:  \"Rods & rings\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nucleoplasm': 0,\n",
       " 'Nuclear membrane': 1,\n",
       " 'Nucleoli': 2,\n",
       " 'Nucleoli fibrillar center': 3,\n",
       " 'Nuclear speckles': 4,\n",
       " 'Nuclear bodies': 5,\n",
       " 'Endoplasmic reticulum': 6,\n",
       " 'Golgi apparatus': 7,\n",
       " 'Peroxisomes': 8,\n",
       " 'Endosomes': 9,\n",
       " 'Lysosomes': 10,\n",
       " 'Intermediate filaments': 11,\n",
       " 'Actin filaments': 12,\n",
       " 'Focal adhesion sites': 13,\n",
       " 'Microtubules': 14,\n",
       " 'Microtubule ends': 15,\n",
       " 'Cytokinetic bridge': 16,\n",
       " 'Mitotic spindle': 17,\n",
       " 'Microtubule organizing center': 18,\n",
       " 'Centrosome': 19,\n",
       " 'Lipid droplets': 20,\n",
       " 'Plasma membrane': 21,\n",
       " 'Cell junctions': 22,\n",
       " 'Mitochondria': 23,\n",
       " 'Aggresome': 24,\n",
       " 'Cytosol': 25,\n",
       " 'Cytoplasmic bodies': 26,\n",
       " 'Rods & rings': 27}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will become handy. Wait for it\n",
    "rev_labels_dict = dict([v, k] for k, v in labels_dict.items())\n",
    "rev_labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "      <th>nb_labels</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "      <td>2</td>\n",
       "      <td>[16, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "      <td>4</td>\n",
       "      <td>[7, 1, 2, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target  nb_labels        labels\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0          2       [16, 0]\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0          4  [7, 1, 2, 0]\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5          1           [5]\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1          1           [1]\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18          1          [18]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"labels\"] = [list(map(int, i.split())) for i in train_df['Target']]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(df_labels, plot=False, figsize=(20,10), title=None, xlabel=None, ylabel=None):\n",
    "    sample_labels_count = Counter()\n",
    "    \n",
    "    # Update the counter \n",
    "    for label in df_labels:\n",
    "        for l in label:\n",
    "            sample_labels_count[labels_dict[l]]+=1\n",
    "    \n",
    "    # Plot \n",
    "    if plot:\n",
    "        plt.figure(figsize=(20,15))\n",
    "        sns.barplot(x=list(sample_labels_count.values()), y=list(sample_labels_count.keys()), color=color[3], orient='h')\n",
    "        if title:\n",
    "            plt.title(title, fontsize=14)\n",
    "        if xlabel:\n",
    "            plt.xlabel(xlabel, fontsize=14)\n",
    "        if ylabel:\n",
    "            plt.ylabel(ylabel, fontsize=14)\n",
    "        plt.show()\n",
    "    \n",
    "    return sample_labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the distribution for different label counts in each sample\n",
    "single_labels_df = train_df[(train_df['nb_labels']==1)]['labels']\n",
    "single_labels_count = count_labels(single_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Nuclear bodies': 983,\n",
       "         'Nuclear membrane': 271,\n",
       "         'Microtubule organizing center': 314,\n",
       "         'Nucleoplasm': 2414,\n",
       "         'Golgi apparatus': 1163,\n",
       "         'Mitochondria': 1653,\n",
       "         'Plasma membrane': 1058,\n",
       "         'Cytosol': 1470,\n",
       "         'Intermediate filaments': 601,\n",
       "         'Focal adhesion sites': 157,\n",
       "         'Actin filaments': 232,\n",
       "         'Nucleoli': 808,\n",
       "         'Lipid droplets': 98,\n",
       "         'Nucleoli fibrillar center': 654,\n",
       "         'Microtubules': 484,\n",
       "         'Centrosome': 522,\n",
       "         'Endoplasmic reticulum': 622,\n",
       "         'Nuclear speckles': 1077,\n",
       "         'Cytoplasmic bodies': 134,\n",
       "         'Cell junctions': 213,\n",
       "         'Peroxisomes': 31,\n",
       "         'Aggresome': 122,\n",
       "         'Cytokinetic bridge': 27,\n",
       "         'Endosomes': 17,\n",
       "         'Rods & rings': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{983: 'Nuclear bodies',\n",
       " 271: 'Nuclear membrane',\n",
       " 314: 'Microtubule organizing center',\n",
       " 2414: 'Nucleoplasm',\n",
       " 1163: 'Golgi apparatus',\n",
       " 1653: 'Mitochondria',\n",
       " 1058: 'Plasma membrane',\n",
       " 1470: 'Cytosol',\n",
       " 601: 'Intermediate filaments',\n",
       " 157: 'Focal adhesion sites',\n",
       " 232: 'Actin filaments',\n",
       " 808: 'Nucleoli',\n",
       " 98: 'Lipid droplets',\n",
       " 654: 'Nucleoli fibrillar center',\n",
       " 484: 'Microtubules',\n",
       " 522: 'Centrosome',\n",
       " 622: 'Endoplasmic reticulum',\n",
       " 1077: 'Nuclear speckles',\n",
       " 134: 'Cytoplasmic bodies',\n",
       " 213: 'Cell junctions',\n",
       " 31: 'Peroxisomes',\n",
       " 122: 'Aggresome',\n",
       " 27: 'Cytokinetic bridge',\n",
       " 17: 'Endosomes',\n",
       " 1: 'Rods & rings'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make another dict but with reversed order of label and counts\n",
    "rev_single_labels_count = dict([v,k] for k,v in single_labels_count.items())\n",
    "rev_single_labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Nucleoplasm', 2414),\n",
       " ('Mitochondria', 1653),\n",
       " ('Cytosol', 1470),\n",
       " ('Golgi apparatus', 1163),\n",
       " ('Nuclear speckles', 1077),\n",
       " ('Plasma membrane', 1058),\n",
       " ('Nuclear bodies', 983),\n",
       " ('Nucleoli', 808),\n",
       " ('Nucleoli fibrillar center', 654),\n",
       " ('Endoplasmic reticulum', 622),\n",
       " ('Intermediate filaments', 601),\n",
       " ('Centrosome', 522),\n",
       " ('Microtubules', 484),\n",
       " ('Microtubule organizing center', 314),\n",
       " ('Nuclear membrane', 271),\n",
       " ('Actin filaments', 232),\n",
       " ('Cell junctions', 213),\n",
       " ('Focal adhesion sites', 157),\n",
       " ('Cytoplasmic bodies', 134),\n",
       " ('Aggresome', 122),\n",
       " ('Lipid droplets', 98),\n",
       " ('Peroxisomes', 31),\n",
       " ('Cytokinetic bridge', 27),\n",
       " ('Endosomes', 17),\n",
       " ('Rods & rings', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the counter object in descending order\n",
    "single_labels = sorted(single_labels_count.items(), key=lambda pair: pair[1], reverse=True)\n",
    "single_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2414, 1653, 1470, 1163, 1077, 1058,  983,  808,  654,  622,  601,\n",
       "        522,  484,  314,  271,  232,  213,  157,  134,  122,   98,   31,\n",
       "         27,   17,    1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_array = np.array([x[1] for x in single_labels])\n",
    "count_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Roads & Rings` is a single training example. Even though we can augment this but I think from competition point of view, it's not worth it. Let the classifier ignore it as of now. We can think about this later.\n",
    "\n",
    "Before doing data augmentation here are the few points to keep in mind:\n",
    "* Doing data augmentation on examples where there is only one label makes more sense as you are generating augmented data for that label only. If you do only examples where there are more than one label present, we might end up making the imbalance much worse\n",
    "\n",
    "\n",
    "* There are two options for doing data augmentation here\n",
    "    * **On the fly** This will save a lot of disk space but training will be slower as we will be checking the labels for which we want to do augmenation in every batch. \n",
    "    * **Augment and save** The other option is to perform augmentation on the labels you are interested in and save the augmented samples on the disk. We might end up using quite a bit of disk space but in this scenario the training will be blazingly fast\n",
    "    \n",
    "    \n",
    "* Random flips are fine but apart from that, we need to take a look at the augmented samples. One mistake during augmentation and we will be scracthing our head for hours checking what went wrong. **Never make the data worse**\n",
    "\n",
    "\n",
    "* We need to find the `min_samples` that we want for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of samples:  1\n",
      "Maximum number of samples:  2414\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum number of samples: \", np.min(count_array))\n",
    "print(\"Maximum number of samples: \", np.max(count_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pct(arr, nb_count_to_consider, total):\n",
    "    \"\"\"\n",
    "    arr: array containing count corresponding to labels\n",
    "    nb_count_to_consider: Number of samples that appear in training data corresponding to a label\n",
    "    total: total number of labels for which there training examples containing only single label\n",
    "    \n",
    "    Returns: pct of the labels that falls in this range\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    samples = len(np.where(arr < nb_count_to_consider)[0])\n",
    "    pct = round((samples/total)*100, 2)\n",
    "    return pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percemtage of labels with less than 50 training examples:  16.0\n",
      "Percemtage of labels with less than 75 training examples:  16.0\n",
      "Percemtage of labels with less than 100 training examples:  20.0\n",
      "Percemtage of labels with less than 200 training examples:  32.0\n",
      "Percemtage of labels with less than 500 training examples:  52.0\n",
      "Percemtage of labels with less than 700 training examples:  68.0\n",
      "Percemtage of labels with less than 1000 training examples:  76.0\n"
     ]
    }
   ],
   "source": [
    "total_labels = len(count_array)\n",
    "print(\"Percemtage of labels with less than 50 training examples: \", count_pct(count_array, 50, total_labels))\n",
    "print(\"Percemtage of labels with less than 75 training examples: \", count_pct(count_array, 75, total_labels))\n",
    "print(\"Percemtage of labels with less than 100 training examples: \", count_pct(count_array, 100, total_labels))\n",
    "print(\"Percemtage of labels with less than 200 training examples: \", count_pct(count_array, 200, total_labels))\n",
    "print(\"Percemtage of labels with less than 500 training examples: \", count_pct(count_array, 500, total_labels))\n",
    "print(\"Percemtage of labels with less than 700 training examples: \", count_pct(count_array, 700, total_labels))\n",
    "print(\"Percemtage of labels with less than 1000 training examples: \", count_pct(count_array, 1000, total_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 52% of the labels that are having less than 500 training samples in  the training dataset. \n",
    "\n",
    "**Note:** We are considering only those labels that occurs solely somehwere in the training dataset. This percentage is the reflection of those labels only, not all the labels.\n",
    "\n",
    "Let us check which are the classes that have less than 500 samples in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([484, 314, 271, 232, 213, 157, 134, 122,  98,  31,  27,  17,   1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_than_500 = count_array[np.where(count_array < 500)]\n",
    "less_than_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes having less than 500 samples in the whole dataset\n",
      "\n",
      "Microtubules\n",
      "Microtubule organizing center\n",
      "Nuclear membrane\n",
      "Actin filaments\n",
      "Cell junctions\n",
      "Focal adhesion sites\n",
      "Cytoplasmic bodies\n",
      "Aggresome\n",
      "Lipid droplets\n",
      "Peroxisomes\n",
      "Cytokinetic bridge\n",
      "Endosomes\n",
      "Rods & rings\n"
     ]
    }
   ],
   "source": [
    "# Print the labels using the reversed dictionary we made above.\n",
    "print(\"Classes having less than 500 samples in the whole dataset\")\n",
    "print(\"\")\n",
    "\n",
    "for item in less_than_500:\n",
    "    print(rev_single_labels_count[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
